#version: "3.7"

services:
  # --- CỤM HADOOP (HDFS) ---
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - "9870:9870"
      - "9000:9000"
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
      - HADOOP_HEAPSIZE=512
    env_file:
      - ./hadoop.env
    networks:
      - big-data-net

  datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode1
    restart: always
    volumes:
      - hadoop_datanode1:/hadoop/dfs/data
    environment:
      - SERVICE_PRECONDITION=namenode:9870
      - HADOOP_HEAPSIZE=512
    depends_on:
      - namenode
    env_file:
      - ./hadoop.env
    networks:
      - big-data-net

  datanode2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode2
    restart: always
    volumes:
      - hadoop_datanode2:/hadoop/dfs/data
    environment:
      - SERVICE_PRECONDITION=namenode:9870
      - HADOOP_HEAPSIZE=512
    depends_on:
      - namenode
    env_file:
      - ./hadoop.env
    networks:
      - big-data-net

  # --- CỤM SPARK ---
  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master
    restart: always
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - SPARK_DAEMON_MEMORY=1024m
    env_file:
      - ./hadoop.env
    networks:
      - big-data-net

  spark-worker-1:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1536m
      - SPARK_EXECUTOR_MEMORY=1536m
    env_file:
      - ./hadoop.env
    networks:
      - big-data-net

  spark-worker-2:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1536m
      - SPARK_EXECUTOR_MEMORY=1536m
    env_file:
      - ./hadoop.env
    networks:
      - big-data-net

  # --- DATABASE & ETL ---
  postgres-db:
    # Nâng cấp lên version ổn định hơn
    image: postgres:13
    container_name: postgres-db
    hostname: postgres-db
    restart: unless-stopped
    environment:
      - POSTGRES_USER=etl_user
      - POSTGRES_PASSWORD=etlUser@123
      - POSTGRES_DB=etl_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5433:5432"
    networks:
      - big-data-net

  nifi:
    image: apache/nifi:1.25.0
    container_name: nifi
    hostname: nifi
    restart: unless-stopped
    ports:
      - "8443:8443"
    environment:
      # Cấu hình HTTPS (bắt buộc với bản mới)
      - NIFI_WEB_HTTPS_PORT=8443
      - NIFI_WEB_HTTPS_HOST=0.0.0.0
      # Key mã hóa (bắt buộc)
      - NIFI_SENSITIVE_PROPS_KEY=BiMat_KhongDuocTietLo_123456789
      # TẠO USER ADMIN (Pass tối thiểu 12 ký tự)
      - NIFI_SINGLE_USER_CREDENTIALS_USERNAME=admin
      - NIFI_SINGLE_USER_CREDENTIALS_PASSWORD=AdminPassword123
      
      # Cấu hình bộ nhớ
      - NIFI_JVM_HEAP_INIT=512m
      - NIFI_JVM_HEAP_MAX=1024m
    volumes:
      - nifi_data:/opt/nifi/nifi-current/data
      - nifi_conf:/opt/nifi/nifi-current/conf
      - ./nifi_drivers:/opt/nifi/nifi-current/drivers
      - ./nifi_hadoop_config:/opt/nifi/hadoop_config
      - ./realtime-data:/opt/nifi/nifi-current/realtime-data
    depends_on:
      - namenode
      - postgres-db
    networks:
      - big-data-net

  # --- CỤM HIVE (MetaStore + Server) ---
  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-metastore
    restart: always
    env_file:
      - ./hadoop.env
    environment:
      - HIVE_SITE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://postgres-db:5432/etl_db
      - HIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName=org.postgresql.Driver
      - HIVE_SITE_CONF_javax_jdo_option_ConnectionUserName=etl_user
      - HIVE_SITE_CONF_javax_jdo_option_ConnectionPassword=etlUser@123
      # QUAN TRỌNG: Phải set true để tự tạo bảng metadata lần đầu
      - HIVE_SITE_CONF_datanucleus_autoCreateSchema=true
      - HIVE_SITE_CONF_hive_metastore_schema_verification=false
      - SERVICE_PRECONDITION=namenode:9870 postgres-db:5432
      - HADOOP_HEAPSIZE=1024
    command: ["/opt/hive/bin/hive", "--service", "metastore"]
    depends_on:
      - postgres-db
      - namenode
    ports:
      - "9083:9083"
    networks:
      - big-data-net

  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    restart: always
    env_file:
      - ./hadoop.env
    environment:
      - HIVE_SITE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://postgres-db:5432/etl_db
      - HIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName=org.postgresql.Driver
      - HIVE_SITE_CONF_javax_jdo_option_ConnectionUserName=etl_user
      - HIVE_SITE_CONF_javax_jdo_option_ConnectionPassword=etlUser@123
      - HIVE_SITE_CONF_hive_metastore_schema_verification=false
      - SERVICE_PRECONDITION=hive-metastore:9083
      - HADOOP_HEAPSIZE=2048
      - HADOOP_OPTS=-Djava.security.egd=file:/dev/./urandom
      - HIVE_SITE_CONF_hive_server2_authentication=NOSASL
    depends_on:
      - hive-metastore
    ports:
      - "10000:10000"
    networks:
      - big-data-net
    command: ["/opt/hive/bin/hive", "--service", "hiveserver2", "--hiveconf", "hive.root.logger=INFO,console"]

volumes:
  hadoop_namenode:
  hadoop_datanode1:
  hadoop_datanode2:
  postgres_data:
  nifi_data:
  nifi_conf:

networks:
  big-data-net:
    driver: bridge